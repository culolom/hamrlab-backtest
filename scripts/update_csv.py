"""
Auto-update adjusted-price CSVs (Smart Append & Split Detection)
- Automatically detects Stock Splits (like 00663L in 2025)
- Fixes yfinance MultiIndex column issues
"""

from __future__ import annotations
from pathlib import Path
from datetime import datetime, timedelta
import re
import pandas as pd
import yfinance as yf

# -----------------------------------------------------
# Paths & Config
# -----------------------------------------------------
DATA_DIR = Path("data")
SYMBOLS_FILE = Path("symbols.txt")

# -----------------------------------------------------
# Normalize symbol
# -----------------------------------------------------
def normalize_symbol(sym: str) -> str:
    s = sym.strip().upper()
    if s.endswith(".TW"):
        return s
    if re.match(r"^\d+[A-Z]*$", s):
        return s + ".TW"
    return s

# -----------------------------------------------------
# Helper: Fix yfinance MultiIndex columns
# -----------------------------------------------------
def clean_yfinance_columns(df: pd.DataFrame) -> pd.DataFrame:
    # å¦‚æžœæ˜¯å¤šå±¤ç´¢å¼• (Price, Ticker)ï¼Œåªä¿ç•™ç¬¬ä¸€å±¤ (Price)
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.get_level_values(0)
    return df

# -----------------------------------------------------
# Load existing CSV
# -----------------------------------------------------
def load_existing(symbol: str) -> pd.DataFrame | None:
    path = DATA_DIR / f"{symbol}.csv"
    if not path.exists():
        return None

    try:
        # å˜—è©¦è®€å–ï¼Œè™•ç†å¯èƒ½çš„å¤šè¡Œ Header å•é¡Œ
        # å‡è¨­æ¨™æº–æ ¼å¼åªæœ‰ä¸€è¡Œ headerï¼Œå¦‚æžœæ˜¯äº‚æŽ‰çš„æ ¼å¼å¯èƒ½éœ€è¦æ›´è¤‡é›œçš„æ¸…æ´—
        # é€™è£¡ç°¡å–®è®€å–ï¼Œå¦‚æžœå‡ºéŒ¯å°±å›žå‚³ None è®“å®ƒé‡å»º
        df = pd.read_csv(path, index_col=0, parse_dates=True)
        
        # ç°¡å–®é©—è­‰æ˜¯å¦æœ‰éœ€è¦çš„æ¬„ä½
        if "Close" not in df.columns:
            # å¯èƒ½æ˜¯å› ç‚ºä¹‹å‰çš„ MultiIndex å­˜æª”å°Žè‡´ header éŒ¯äº‚ï¼Œè¦–ç‚ºæå£ž
            return None
            
        df = df.sort_index()
        return df
    except Exception as e:
        print(f"âš  CSV corrupted for {symbol} ({e}), rebuilding...")
        return None

# -----------------------------------------------------
# Download Full History (Overwrite)
# -----------------------------------------------------
def download_full_history(symbol: str):
    print(f"ðŸ“¦ Downloading FULL history for {symbol}...")
    df = yf.download(symbol, period="max", auto_adjust=True, progress=False)
    df = clean_yfinance_columns(df)
    
    if df.empty:
        print(f"âŒ FAILED: no data for {symbol}")
        return

    df = df[["Close", "Volume"]]
    df.index.name = "Date"
    df.to_csv(DATA_DIR / f"{symbol}.csv")
    print(f"âœ… Saved fresh CSV for {symbol} ({len(df)} rows)")

# -----------------------------------------------------
# Update single symbol CSV (Smart Update)
# -----------------------------------------------------
def update_symbol(symbol: str):
    DATA_DIR.mkdir(exist_ok=True)
    existing = load_existing(symbol)

    # 1. å¦‚æžœæ²’æœ‰èˆŠæª”ï¼Œç›´æŽ¥ä¸‹è¼‰å…¨é‡
    if existing is None or existing.empty:
        download_full_history(symbol)
        return

    # 2. æª¢æŸ¥åƒ¹æ ¼ä¸€è‡´æ€§ (Split Detection)
    last_date = existing.index[-1]
    
    # ä¸‹è¼‰é€™å¹¾å¤©çš„è³‡æ–™ (åŒ…å« last_date) ç”¨ä¾†æ¯”å°
    # å¾€å›žå¤šæŠ“ 5 å¤©ç¢ºä¿æœ‰é‡ç–Šè³‡æ–™
    check_start = last_date - timedelta(days=5)
    
    print(f"ðŸ” Checking {symbol} consistency since {last_date.date()}...")
    
    new_data = yf.download(
        symbol, 
        start=check_start.strftime("%Y-%m-%d"), 
        end=None, # åˆ°æœ€æ–°
        auto_adjust=True, 
        progress=False
    )
    new_data = clean_yfinance_columns(new_data)
    
    if new_data.empty:
        print(f"â­ No new data found for {symbol}")
        return

    # æ¯”å° last_date ç•¶å¤©çš„åƒ¹æ ¼
    if last_date in new_data.index:
        old_close = existing.loc[last_date, "Close"]
        new_close = new_data.loc[last_date, "Close"]
        
        # è™•ç†å¯èƒ½çš„ Series (å¦‚æžœæœ‰é‡è¤‡ index)
        if isinstance(old_close, pd.Series): old_close = old_close.iloc[-1]
        if isinstance(new_close, pd.Series): new_close = new_close.iloc[-1]

        # è¨ˆç®—åƒ¹æ ¼å·®ç•°æ¯”ä¾‹
        ratio = abs(new_close - old_close) / old_close
        
        # å¦‚æžœå·®ç•°è¶…éŽ 10%ï¼Œè¦–ç‚ºç™¼ç”Ÿæ‹†è‚¡/é™¤æ¬Šæ¯ï¼Œè§¸ç™¼å…¨é‡æ›´æ–°
        if ratio > 0.1:
            print(f"âš  Split/Adjustment detected! ({old_close:.2f} vs {new_close:.2f})")
            print("â™» Triggering FULL re-download to fix history...")
            download_full_history(symbol)
            return
    
    # 3. å¦‚æžœåƒ¹æ ¼ä¸€è‡´ï¼ŒåŸ·è¡Œ Append
    # åªå– last_date ä¹‹å¾Œçš„æ–°è³‡æ–™
    new_rows = new_data[new_data.index > last_date].copy()
    
    if new_rows.empty:
        print(f"â­ {symbol} already up-to-date")
        return

    new_rows = new_rows[["Close", "Volume"]]
    new_rows.index.name = "Date"

    merged = pd.concat([existing, new_rows])
    merged = merged[~merged.index.duplicated(keep="last")]
    merged = merged.sort_index()

    merged.to_csv(DATA_DIR / f"{symbol}.csv")
    print(f"âœ… Appended {len(new_rows)} rows to {symbol}")

# -----------------------------------------------------
# Read symbols.txt
# -----------------------------------------------------
def load_symbols() -> list[str]:
    if not SYMBOLS_FILE.exists():
        # Fallback for demo
        return ["00663L.TW"]

    with open(SYMBOLS_FILE, "r", encoding="utf-8") as f:
        return [normalize_symbol(line.strip()) for line in f if line.strip() and not line.startswith("#")]

# -----------------------------------------------------
# Main
# -----------------------------------------------------
def main():
    symbols = load_symbols()
    for sym in symbols:
        print("\n" + "="*30)
        try:
            update_symbol(sym)
        except Exception as e:
            print(f"âš  ERROR updating {sym}: {e}")

if __name__ == "__main__":
    main()
