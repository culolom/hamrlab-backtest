"""
Auto-update adjusted-price CSVs (Self-Healing Version)
- Automatically detects & repairs missing Stock Splits (like 00663L)
- Forces continuity even if Yahoo Finance data is broken
"""

from __future__ import annotations
from pathlib import Path
from datetime import datetime, timedelta
import re
import pandas as pd
import yfinance as yf
import numpy as np

# -----------------------------------------------------
# Paths & Config
# -----------------------------------------------------
DATA_DIR = Path("data")
SYMBOLS_FILE = Path("symbols.txt")

# -----------------------------------------------------
# Normalize symbol
# -----------------------------------------------------
def normalize_symbol(sym: str) -> str:
    s = sym.strip().upper()
    if s.endswith(".TW"):
        return s
    if re.match(r"^\d+[A-Z]*$", s):
        return s + ".TW"
    return s

# -----------------------------------------------------
# Helper: Fix yfinance MultiIndex columns
# -----------------------------------------------------
def clean_yfinance_columns(df: pd.DataFrame) -> pd.DataFrame:
    # Fix (Price, Ticker) -> Price
    if isinstance(df.columns, pd.MultiIndex):
        try:
            df.columns = df.columns.get_level_values(0)
        except IndexError:
            pass
    return df

# -----------------------------------------------------
# CORE: Detect & Repair Splits Manually
# -----------------------------------------------------
def detect_and_repair_splits(df: pd.DataFrame, symbol: str) -> pd.DataFrame:
    """
    Scans for massive price discontinuities (>50% drop or >100% gain)
    and back-adjusts historical data if Yahoo missed the split.
    """
    if df.empty or len(df) < 2:
        return df

    # éœ€è¦ Open æ¬„ä½ä¾†è¨ˆç®—ç²¾ç¢ºçš„ Split Ratio (Open[t] / Close[t-1])
    # å¦‚æœåªæœ‰ Closeï¼Œé€™ä¸€æ­¥åªèƒ½ç”¨ Close ä¼°ç®—
    has_open = 'Open' in df.columns

    # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ–ç‡
    closes = df['Close']
    prev_closes = closes.shift(1)
    
    # åµæ¸¬é–¾å€¼ï¼šè·Œå¹… > 40% (0.6) æˆ– æ¼²å¹… > 80% (1.8)
    # 00663L 1æ‹†7 ç´„è·Œ 85%
    drops = closes / prev_closes
    
    # æ‰¾å‡ºç•°å¸¸é» (å¿½ç•¥ç¬¬ä¸€ç­† NaN)
    split_candidates = drops[(drops < 0.6) | (drops > 1.8)].dropna()

    if split_candidates.empty:
        return df

    # é–‹å§‹ä¿®å¾©
    df_fixed = df.copy()
    
    for date, ratio_raw in split_candidates.items():
        # å–å¾—è©²æ—¥æœŸçš„æ•´æ•¸ç´¢å¼•ä½ç½®
        loc_idx = df_fixed.index.get_loc(date)
        if loc_idx == 0: continue

        # è¨ˆç®—ä¿®æ­£å› å­ (Split Factor)
        # ç†æƒ³å…¬å¼ï¼š Factor = Previous Close / Current Open
        # å› ç‚º Split é€šå¸¸ç™¼ç”Ÿåœ¨é–‹ç›¤å‰ï¼ŒOpen æ‡‰è©²å·²ç¶“æ˜¯åˆ†å‰²å¾Œçš„åƒ¹æ ¼
        prev_close = df_fixed['Close'].iloc[loc_idx - 1]
        
        if has_open:
            curr_open = df_fixed['Open'].iloc[loc_idx]
            # é¿å… Open ç‚º 0 æˆ– NaN
            if pd.isna(curr_open) or curr_open == 0:
                curr_open = df_fixed['Close'].iloc[loc_idx]
        else:
            curr_open = df_fixed['Close'].iloc[loc_idx]

        # Factor > 1 ä»£è¡¨æ‹†è‚¡ (åƒ¹æ ¼è®Šå°ï¼Œå¦‚ 175 -> 25ï¼ŒFactor=7)
        # Factor < 1 ä»£è¡¨åå‘æ‹†è‚¡ (åƒ¹æ ¼è®Šå¤§)
        factor = prev_close / curr_open

        # ç°¡å–®éæ¿¾ï¼šå¦‚æœé€™åªæ˜¯å¸‚å ´å¤§å´©ç›¤ (ä¾‹å¦‚è·Œ 10-20%)ï¼ŒFactor æœƒæ¥è¿‘ 1.1-1.2
        # æˆ‘å€‘åªè™•ç† Factor > 1.5 æˆ– Factor < 0.6 çš„æƒ…æ³
        if 0.6 < factor < 1.5:
            continue

        print(f"ğŸ”§ REPAIR: Detected missing split for {symbol} on {date.date()}")
        print(f"   Before: {prev_close:.2f} -> {curr_open:.2f} (Factor: {factor:.4f})")
        
        # åŸ·è¡Œå›æº¯ä¿®æ­£ (Back Adjustment)
        # èˆŠåƒ¹æ ¼å…¨éƒ¨é™¤ä»¥ Factor (ä¾‹å¦‚ 175 / 7 = 25)
        # èˆŠæˆäº¤é‡å…¨éƒ¨ä¹˜ä»¥ Factor (è‚¡æ•¸è®Šå¤š)
        mask = df_fixed.index < date
        
        cols_to_fix = ['Close', 'Open', 'High', 'Low']
        for col in cols_to_fix:
            if col in df_fixed.columns:
                df_fixed.loc[mask, col] = df_fixed.loc[mask, col] / factor
        
        if 'Volume' in df_fixed.columns:
            df_fixed.loc[mask, 'Volume'] = df_fixed.loc[mask, 'Volume'] * factor

        print(f"   âœ… History adjusted. New prev close: {df_fixed.loc[mask, 'Close'].iloc[-1]:.2f}")

    return df_fixed

# -----------------------------------------------------
# Download & Update Logic
# -----------------------------------------------------
def download_data(symbol: str, start=None, mode="full") -> pd.DataFrame:
    """Generic download wrapper that fetches Open/Close/Volume"""
    print(f"â¬‡ Fetching {symbol} ({mode})...")
    
    df = yf.download(
        symbol,
        start=start,
        period="max" if mode=="full" else None,
        auto_adjust=True, # å˜—è©¦è®“ Yahoo è‡ªå‹•èª¿æ•´
        progress=False
    )
    df = clean_yfinance_columns(df)
    
    # ç¢ºä¿æœ‰éœ€è¦çš„æ¬„ä½ï¼Œè‹¥æ²’æœ‰å‰‡è£œ NaN (é¿å…å ±éŒ¯)
    required = ['Open', 'Close', 'Volume']
    for col in required:
        if col not in df.columns:
            df[col] = np.nan
            
    return df

def update_symbol(symbol: str):
    DATA_DIR.mkdir(exist_ok=True)
    csv_path = DATA_DIR / f"{symbol}.csv"
    
    # 1. Load Existing
    existing = None
    if csv_path.exists():
        try:
            existing = pd.read_csv(csv_path, index_col=0, parse_dates=True)
            if "Close" not in existing.columns: existing = None
        except:
            existing = None

    # 2. Determine Fetch Strategy
    if existing is None or existing.empty:
        # Full Download
        new_data = download_data(symbol, mode="full")
    else:
        # Append Update
        last_date = existing.index[-1]
        start_date = (last_date - timedelta(days=10)).strftime("%Y-%m-%d") # å¤šæŠ“å¹¾å¤©ç”¨ä¾†æ¥åˆ
        print(f"ğŸ“„ Appending {symbol} from {start_date}...")
        
        fresh = download_data(symbol, start=start_date, mode="append")
        
        # åˆä½µèˆŠèˆ‡æ–° (é€™è£¡é‚„æ²’ä¿®å¾©)
        # å…ˆæŠŠ fresh ä¸­é‡ç–Šçš„éƒ¨åˆ†è“‹é existing (ä»¥æœ€æ–°çš„æ•¸æ“šç‚ºæº–)
        existing = existing[existing.index < pd.Timestamp(start_date)]
        new_data = pd.concat([existing, fresh])
        new_data = new_data[~new_data.index.duplicated(keep='last')]
        new_data = new_data.sort_index()

    if new_data.empty:
        print(f"âš  No data for {symbol}")
        return

    # 3. åŸ·è¡Œã€Œè‡ªæˆ‘ä¿®å¾©ã€æª¢æ¸¬ (é—œéµæ­¥é©Ÿï¼)
    # ç„¡è«–æ˜¯æ–°ä¸‹è¼‰é‚„æ˜¯åˆä½µå¾Œï¼Œéƒ½è¦æª¢æŸ¥æ˜¯å¦æœ‰ã€Œå‡å´©ç›¤ã€
    repaired_data = detect_and_repair_splits(new_data, symbol)

    # 4. Save (åªä¿ç•™ Close, Volume ä»¥ç¯€çœç©ºé–“ï¼Œæˆ–è€…ä¿ç•™ Open ä¹Ÿå¯ä»¥)
    # é€™è£¡ä¾ç…§æ‚¨çš„éœ€æ±‚åªç•™ Date, Close, Volume
    final_output = repaired_data[["Close", "Volume"]].copy()
    final_output.index.name = "Date"
    
    final_output.to_csv(csv_path)
    print(f"âœ… Saved {symbol} ({len(final_output)} rows)")

# -----------------------------------------------------
# Main
# -----------------------------------------------------
def main():
    if not SYMBOLS_FILE.exists():
        # Demo mode if file missing
        print("âš  symbols.txt missing, using demo list.")
        symbols = ["00663L.TW"] 
    else:
        with open(SYMBOLS_FILE, "r", encoding="utf-8") as f:
            symbols = [normalize_symbol(line.strip()) for line in f if line.strip() and not line.startswith("#")]

    for sym in symbols:
        print("-" * 40)
        try:
            update_symbol(sym)
        except Exception as e:
            print(f"âŒ Error {sym}: {e}")

if __name__ == "__main__":
    main()
